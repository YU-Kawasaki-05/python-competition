{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# [ベースライン] NFL Draft Prediction - ローカル環境版\n",
        "\n",
        "本ノートブックでは、ベースラインモデルをローカル環境で実行し、**ベースラインスコア0.80792を超える**ことを目標とします。\n",
        "\n",
        "## 目標\n",
        "- ベースラインモデルの理解と実行\n",
        "- 提出ファイルの作成\n",
        "- スコア0.80792の達成確認\n",
        "- 改善ポイントの特定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. セットアップ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ライブラリのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "\n",
        "# 設定\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"ライブラリの読み込み完了\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. データ読み込み\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データ読み込み\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n",
        "sample_submission = pd.read_csv('data/sample_submission_6_20修正.csv')\n",
        "\n",
        "print('Train:', train.shape)\n",
        "print('Test:', test.shape)\n",
        "print('Sample submission:', sample_submission.shape)\n",
        "\n",
        "# データの確認\n",
        "print(\"\\n=== 目的変数の確認 ===\")\n",
        "print(f\"Drafted平均値: {train['Drafted'].mean():.5f}\")\n",
        "print(f\"Drafted分布:\")\n",
        "print(train['Drafted'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. 欠損値の確認\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 欠損値の確認\n",
        "print(\"=== 訓練データの欠損値 ===\")\n",
        "train_missing = train.isnull().sum()\n",
        "print(train_missing[train_missing > 0])\n",
        "\n",
        "print(\"\\n=== テストデータの欠損値 ===\")\n",
        "test_missing = test.isnull().sum()\n",
        "print(test_missing[test_missing > 0])\n",
        "\n",
        "# 欠損率の計算\n",
        "missing_ratio_train = train_missing[train_missing > 0] / len(train) * 100\n",
        "missing_ratio_test = test_missing[test_missing > 0] / len(test) * 100\n",
        "\n",
        "print(f\"\\n=== 欠損率(%) ===\")\n",
        "print(\"Train:\", missing_ratio_train.round(1))\n",
        "print(\"Test:\", missing_ratio_test.round(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. 前処理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 前処理関数の定義\n",
        "def preprocess_data(train_df, test_df):\n",
        "    # データのコピーを作成\n",
        "    train_processed = train_df.copy()\n",
        "    test_processed = test_df.copy()\n",
        "    \n",
        "    # 全データを結合して一括前処理\n",
        "    all_data = pd.concat([train_processed, test_processed], ignore_index=True)\n",
        "    \n",
        "    # 1. 欠損値処理（中央値で補完）\n",
        "    numerical_cols = all_data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numerical_cols = [col for col in numerical_cols if col not in ['Id', 'Drafted']]\n",
        "    \n",
        "    for col in numerical_cols:\n",
        "        median_val = all_data[col].median()\n",
        "        all_data[col].fillna(median_val, inplace=True)\n",
        "    \n",
        "    # 2. カテゴリ変数のラベルエンコーディング\n",
        "    categorical_cols = all_data.select_dtypes(include=['object']).columns.tolist()\n",
        "    \n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        all_data[col] = le.fit_transform(all_data[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "    \n",
        "    # 3. データを分割\n",
        "    train_len = len(train_processed)\n",
        "    train_processed = all_data[:train_len].copy()\n",
        "    test_processed = all_data[train_len:].copy()\n",
        "    \n",
        "    # 4. 特徴量とターゲットを分離\n",
        "    feature_cols = [col for col in train_processed.columns if col not in ['Id', 'Drafted']]\n",
        "    \n",
        "    X_train = train_processed[feature_cols]\n",
        "    y_train = train_processed['Drafted']\n",
        "    X_test = test_processed[feature_cols]\n",
        "    \n",
        "    print(f\"特徴量数: {len(feature_cols)}\")\n",
        "    print(f\"訓練データサイズ: {X_train.shape}\")\n",
        "    print(f\"テストデータサイズ: {X_test.shape}\")\n",
        "    print(f\"特徴量: {feature_cols}\")\n",
        "    \n",
        "    return X_train, y_train, X_test, feature_cols, label_encoders\n",
        "\n",
        "# 前処理実行\n",
        "X_train, y_train, X_test, feature_cols, label_encoders = preprocess_data(train, test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. ベースラインモデルの訓練と交差検証\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ベースラインモデルの定義\n",
        "def train_baseline_model(X_train, y_train, n_splits=5, random_state=42):\n",
        "    # ランダムフォレスト分類器\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=random_state,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    # Stratified K-Fold交差検証\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    \n",
        "    cv_scores = []\n",
        "    oof_predictions = np.zeros(len(X_train))\n",
        "    \n",
        "    print(\"=== 交差検証実行 ===\")\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
        "        # 訓練・検証データの分割\n",
        "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "        \n",
        "        # モデル訓練\n",
        "        model.fit(X_fold_train, y_fold_train)\n",
        "        \n",
        "        # 予測\n",
        "        val_predictions = model.predict_proba(X_fold_val)[:, 1]\n",
        "        oof_predictions[val_idx] = val_predictions\n",
        "        \n",
        "        # AUCスコア計算\n",
        "        auc_score = roc_auc_score(y_fold_val, val_predictions)\n",
        "        cv_scores.append(auc_score)\n",
        "        \n",
        "        print(f\"Fold {fold + 1}: AUC = {auc_score:.5f}\")\n",
        "    \n",
        "    # 最終的なOOF AUCスコア\n",
        "    oof_auc = roc_auc_score(y_train, oof_predictions)\n",
        "    \n",
        "    print(f\"\\n=== 交差検証結果 ===\")\n",
        "    print(f\"平均AUC: {np.mean(cv_scores):.5f} (+/- {np.std(cv_scores):.5f})\")\n",
        "    print(f\"OOF AUC: {oof_auc:.5f}\")\n",
        "    \n",
        "    return model, oof_predictions, cv_scores, oof_auc\n",
        "\n",
        "# ベースラインモデルの訓練\n",
        "baseline_model, oof_pred, cv_scores, oof_auc = train_baseline_model(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. 特徴量重要度の分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量重要度の分析\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': baseline_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"=== 特徴量重要度（上位10） ===\")\n",
        "print(feature_importance.head(10))\n",
        "\n",
        "# 特徴量重要度の可視化\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_features = feature_importance.head(15)\n",
        "sns.barplot(data=top_features, x='importance', y='feature')\n",
        "plt.title('特徴量重要度（上位15）')\n",
        "plt.xlabel('重要度')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 全データでモデルを再訓練\n",
        "print(\"=== 全データでのモデル再訓練 ===\")\n",
        "final_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# テストデータの予測\n",
        "test_predictions = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"テスト予測の統計:\")\n",
        "print(f\"  平均: {test_predictions.mean():.5f}\")\n",
        "print(f\"  最小: {test_predictions.min():.5f}\")\n",
        "print(f\"  最大: {test_predictions.max():.5f}\")\n",
        "print(f\"  標準偏差: {test_predictions.std():.5f}\")\n",
        "\n",
        "# 提出ファイルの作成\n",
        "submission = sample_submission.copy()\n",
        "submission['Drafted'] = test_predictions\n",
        "\n",
        "# 提出ファイルの保存\n",
        "submission_filename = 'baseline_submission.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\n=== 提出ファイル作成完了 ===\")\n",
        "print(f\"ファイル名: {submission_filename}\")\n",
        "print(f\"形式確認:\")\n",
        "print(submission.head())\n",
        "print(f\"サイズ: {submission.shape}\")\n",
        "\n",
        "# ベースラインスコアとの比較\n",
        "print(f\"\\n=== ベースライン比較 ===\")\n",
        "print(f\"目標ベースラインスコア: 0.80792\")\n",
        "print(f\"交差検証OOF AUC: {oof_auc:.5f}\")\n",
        "if oof_auc > 0.80792:\n",
        "    print(\"✅ ベースラインスコアを上回りました！\")\n",
        "else:\n",
        "    print(\"❌ ベースラインスコアに届きませんでした。改善が必要です。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. 結果の分析と改善ポイント\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 結果の分析\n",
        "print(\"=== ベースラインモデル総括 ===\")\n",
        "print(f\"1. 交差検証AUC: {oof_auc:.5f}\")\n",
        "print(f\"2. 標準偏差: {np.std(cv_scores):.5f}\")\n",
        "print(f\"3. 使用特徴量数: {len(feature_cols)}\")\n",
        "print(f\"4. 最重要特徴量: {feature_importance.iloc[0]['feature']}\")\n",
        "\n",
        "print(f\"\\n=== 改善ポイントの提案 ===\")\n",
        "print(\"1. 特徴量エンジニアリング:\")\n",
        "print(\"   - BMI、パワーウェイトレシオ等の組み合わせ特徴量\")\n",
        "print(\"   - ポジション別の正規化\")\n",
        "print(\"   - 年度トレンドの考慮\")\n",
        "\n",
        "print(\"\\n2. 欠損値処理の改善:\")\n",
        "print(\"   - ポジション別の中央値/平均値補完\")\n",
        "print(\"   - 多重代入法の検討\")\n",
        "print(\"   - 欠損パターンの特徴量化\")\n",
        "\n",
        "print(\"\\n3. モデルの改善:\")\n",
        "print(\"   - ハイパーパラメータチューニング\")\n",
        "print(\"   - 他のアルゴリズム（LightGBM、XGBoost）の試行\")\n",
        "print(\"   - アンサンブル手法の適用\")\n",
        "\n",
        "print(\"\\n4. バリデーション戦略:\")\n",
        "print(\"   - 年度別の分割検討\")\n",
        "print(\"   - Holdout検証の追加\")\n",
        "\n",
        "# 予測分布の可視化\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(oof_pred, bins=30, alpha=0.7, label='OOF予測', edgecolor='black')\n",
        "plt.hist(y_train, bins=30, alpha=0.7, label='実際のDrafted', edgecolor='black')\n",
        "plt.xlabel('Drafted値')\n",
        "plt.ylabel('頻度')\n",
        "plt.title('OOF予測 vs 実際の分布')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(test_predictions, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
        "plt.xlabel('予測確率')\n",
        "plt.ylabel('頻度')\n",
        "plt.title('テスト予測の分布')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n=== 次のステップ ===\")\n",
        "print(\"1. EDAで発見した特徴量エンジニアリングアイデアの実装\")\n",
        "print(\"2. 複数モデルでの実験\")\n",
        "print(\"3. ハイパーパラメータ最適化\")\n",
        "print(\"4. アンサンブル手法の適用\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
