# NFL Draft Prediction - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å®Ÿè£…
# RandomForest + LightGBM + XGBoostçµ±åˆ

# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier
import lightgbm as lgb
import xgboost as xgb
import warnings

# è¨­å®š
warnings.filterwarnings('ignore')
np.random.seed(42)
pd.set_option('display.max_columns', None)

print("=== NFL Draft Prediction - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«å®Ÿè£…é–‹å§‹ ===")

# æ—¢å­˜ã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ï¼ˆåŒã˜ã‚‚ã®ï¼‰
def create_basic_features(df):
    """åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’ä½œæˆ"""
    df_new = df.copy()
    
    # 1. BMIï¼ˆBody Mass Indexï¼‰
    df_new['BMI'] = df_new['Weight'] / (df_new['Height'] ** 2)
    
    # 2. ãƒ‘ãƒ¯ãƒ¼ãƒ»ã‚¦ã‚§ã‚¤ãƒˆãƒ»ãƒ¬ã‚·ã‚ª
    df_new['Power_Weight_Ratio'] = df_new['Bench_Press_Reps'] / df_new['Weight']
    
    # 3. ã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ»ãƒ‘ãƒ¯ãƒ¼ãƒ»ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå‚ç›´è·³ã³ / 40ãƒ¤ãƒ¼ãƒ‰èµ°ï¼‰
    df_new['Speed_Power_Index'] = df_new['Vertical_Jump'] / df_new['Sprint_40yd']
    
    # 4. ã‚¢ã‚¸ãƒªãƒ†ã‚£ãƒ»ã‚¹ã‚³ã‚¢ï¼ˆ3cone + shuttleï¼‰
    df_new['Agility_Score'] = df_new['Agility_3cone'] + df_new['Shuttle']
    
    # 5. çˆ†ç™ºåŠ›æŒ‡æ¨™ï¼ˆç«‹ã¡å¹…è·³ã³ * å‚ç›´è·³ã³ï¼‰
    df_new['Explosiveness'] = df_new['Broad_Jump'] * df_new['Vertical_Jump']
    
    # 6. ã‚¹ãƒ”ãƒ¼ãƒ‰Ã—çˆ†ç™ºåŠ›
    df_new['Speed_Explosiveness'] = df_new['Explosiveness'] / df_new['Sprint_40yd']
    
    # 7. ä½“æ ¼æŒ‡æ¨™ï¼ˆèº«é•·Ã—ä½“é‡ï¼‰
    df_new['Size_Index'] = df_new['Height'] * df_new['Weight']
    
    # 8. ãƒ™ãƒ³ãƒãƒ—ãƒ¬ã‚¹åŠ¹ç‡ï¼ˆå›æ•°/ä½“é‡Ã—èº«é•·ï¼‰
    df_new['Bench_Efficiency'] = df_new['Bench_Press_Reps'] / df_new['Size_Index']
    
    # 9. å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆã‚«ãƒ†ã‚´ãƒªåŒ–ï¼‰
    df_new['Age_Group'] = pd.cut(df_new['Age'], bins=[0, 21, 23, 30], 
                                labels=['Young', 'Standard', 'Veteran'], 
                                include_lowest=True)
    
    print("åŸºæœ¬ç‰¹å¾´é‡ä½œæˆå®Œäº†")
    return df_new

def create_position_features(df):
    """ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥ã®ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    df_new = df.copy()
    
    # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã®æ­£è¦åŒ–ç‰¹å¾´é‡
    numerical_cols = ['Height', 'Weight', 'Sprint_40yd', 'Vertical_Jump', 
                     'Bench_Press_Reps', 'Broad_Jump', 'Agility_3cone', 'Shuttle']
    
    for col in numerical_cols:
        if col in df_new.columns:
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã®å¹³å‡å€¤ã§æ­£è¦åŒ–
            position_means = df_new.groupby('Position_Type')[col].transform('mean')
            df_new[f'{col}_vs_Position_Mean'] = df_new[col] / position_means
            
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã®æ¨™æº–åå·®ã§æ­£è¦åŒ–
            position_stds = df_new.groupby('Position_Type')[col].transform('std')
            df_new[f'{col}_Position_Zscore'] = (df_new[col] - position_means) / position_stds
    
    # ãƒã‚¸ã‚·ãƒ§ãƒ³ç‰¹åŒ–ã®çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡
    # 1. ã‚ªãƒ•ã‚§ãƒ³ã‚·ãƒ–ãƒ©ã‚¤ãƒ³ç”¨ç‰¹å¾´é‡
    offensive_line_mask = df_new['Position_Type'] == 'offensive_lineman'
    df_new['OL_Strength_Index'] = 0
    df_new.loc[offensive_line_mask, 'OL_Strength_Index'] = (
        df_new.loc[offensive_line_mask, 'Bench_Press_Reps'] * 
        df_new.loc[offensive_line_mask, 'Weight'] / 100
    )
    
    # 2. ã‚¹ã‚­ãƒ«ãƒã‚¸ã‚·ãƒ§ãƒ³ç”¨ç‰¹å¾´é‡
    skill_positions = ['backs_receivers']
    skill_mask = df_new['Position_Type'].isin(skill_positions)
    df_new['Skill_Speed_Index'] = 0
    df_new.loc[skill_mask, 'Skill_Speed_Index'] = (
        df_new.loc[skill_mask, 'Vertical_Jump'] * 
        df_new.loc[skill_mask, 'Broad_Jump'] / 
        df_new.loc[skill_mask, 'Sprint_40yd']
    )
    
    # 3. ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ç”¨ç‰¹å¾´é‡
    defense_positions = ['defensive_lineman', 'line_backer', 'defensive_back']
    defense_mask = df_new['Position_Type'].isin(defense_positions)
    df_new['Defense_Athleticism'] = 0
    df_new.loc[defense_mask, 'Defense_Athleticism'] = (
        (df_new.loc[defense_mask, 'Vertical_Jump'] + 
         df_new.loc[defense_mask, 'Broad_Jump']) / 
        (df_new.loc[defense_mask, 'Sprint_40yd'] + 
         df_new.loc[defense_mask, 'Agility_3cone'])
    )
    
    print("ãƒã‚¸ã‚·ãƒ§ãƒ³ç‰¹åŒ–ç‰¹å¾´é‡ä½œæˆå®Œäº†")
    return df_new

def create_school_features(df):
    """å­¦æ ¡ã«é–¢ã™ã‚‹ç‰¹å¾´é‡ã‚’ä½œæˆ"""
    df_new = df.copy()
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ã£ã¦å­¦æ ¡çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ãï¼‰
    train_data = df_new[df_new['Drafted'].notna()].copy()
    
    # å­¦æ ¡åˆ¥ã®æŒ‡åç‡ã¨é¸æ‰‹æ•°
    school_stats = train_data.groupby('School').agg({
        'Drafted': ['count', 'mean']
    })
    school_stats.columns = ['School_Player_Count', 'School_Draft_Rate']
    
    # 5äººæœªæº€ã®å­¦æ ¡ã¯çµ±è¨ˆãŒä¸å®‰å®šãªã®ã§å¹³å‡å€¤ã§è£œå®Œ
    overall_draft_rate = train_data['Drafted'].mean()
    school_stats.loc[school_stats['School_Player_Count'] < 5, 'School_Draft_Rate'] = overall_draft_rate
    
    # å­¦æ ¡ãƒ—ãƒ¬ã‚¹ãƒ†ãƒ¼ã‚¸ã‚«ãƒ†ã‚´ãƒª
    def categorize_school_prestige(draft_rate, player_count):
        if pd.isna(draft_rate):
            return 'Unknown'
        elif draft_rate >= 0.8:
            return 'Elite'
        elif draft_rate >= 0.6:
            return 'High'
        elif draft_rate >= 0.4:
            return 'Medium'
        else:
            return 'Low'
    
    school_stats['School_Prestige'] = school_stats.apply(
        lambda x: categorize_school_prestige(x['School_Draft_Rate'], x['School_Player_Count']), axis=1
    )
    
    # å…¨ãƒ‡ãƒ¼ã‚¿ã«ãƒãƒ¼ã‚¸
    df_new = df_new.merge(school_stats, left_on='School', right_index=True, how='left')
    
    # æ–°ã—ã„å­¦æ ¡ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã«å­˜åœ¨ï¼‰ã¯å¹³å‡å€¤ã§è£œå®Œ
    df_new['School_Draft_Rate'].fillna(overall_draft_rate, inplace=True)
    df_new['School_Player_Count'].fillna(1, inplace=True)
    df_new['School_Prestige'].fillna('Unknown', inplace=True)
    
    print("å­¦æ ¡ãƒ—ãƒ¬ã‚¹ãƒ†ãƒ¼ã‚¸ç‰¹å¾´é‡ä½œæˆå®Œäº†")
    return df_new

def advanced_missing_value_handling(df):
    """ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®æ¬ æå€¤å‡¦ç†"""
    df_new = df.copy()
    
    # èº«ä½“èƒ½åŠ›ãƒ†ã‚¹ãƒˆç³»ã®åˆ—
    performance_cols = ['Sprint_40yd', 'Vertical_Jump', 'Bench_Press_Reps', 
                       'Broad_Jump', 'Agility_3cone', 'Shuttle']
    
    # 1. æ¬ æãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ãƒ©ã‚°ã®ä½œæˆ
    for col in performance_cols:
        df_new[f'{col}_is_missing'] = df_new[col].isnull().astype(int)
    
    # 2. æ¬ æå€¤ã®ç·æ•°
    df_new['Total_Missing_Tests'] = df_new[[f'{col}_is_missing' for col in performance_cols]].sum(axis=1)
    
    # 3. ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥ã®ä¸­å¤®å€¤ã§è£œå®Œ
    for col in performance_cols:
        if col in df_new.columns:
            # ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã®ä¸­å¤®å€¤
            position_medians = df_new.groupby('Position_Type')[col].median()
            
            for position in position_medians.index:
                mask = (df_new['Position_Type'] == position) & (df_new[col].isnull())
                df_new.loc[mask, col] = position_medians[position]
            
            # æ®‹ã£ãŸæ¬ æå€¤ã¯å…¨ä½“ã®ä¸­å¤®å€¤ã§è£œå®Œ
            overall_median = df_new[col].median()
            df_new[col].fillna(overall_median, inplace=True)
    
    # 4. Age ã®è£œå®Œ
    if 'Age' in df_new.columns:
        # ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥ã®ä¸­å¤®å€¤ã§è£œå®Œ
        age_medians = df_new.groupby('Position_Type')['Age'].median()
        for position in age_medians.index:
            mask = (df_new['Position_Type'] == position) & (df_new['Age'].isnull())
            df_new.loc[mask, 'Age'] = age_medians[position]
        
        # æ®‹ã£ãŸæ¬ æå€¤ã¯å…¨ä½“ã®ä¸­å¤®å€¤ã§è£œå®Œ
        df_new['Age'].fillna(df_new['Age'].median(), inplace=True)
    
    print("æ”¹è‰¯ã•ã‚ŒãŸæ¬ æå€¤å‡¦ç†å®Œäº†")
    return df_new

def encode_categorical_features(df):
    """ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®åŠ¹æœçš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
    df_new = df.copy()
    
    # Label Encodingã™ã‚‹åˆ—
    label_encode_cols = ['School', 'Player_Type', 'Position_Type', 'Position', 
                        'Age_Group', 'School_Prestige']
    
    encoders = {}
    for col in label_encode_cols:
        if col in df_new.columns:
            le = LabelEncoder()
            df_new[col] = le.fit_transform(df_new[col].astype(str))
            encoders[col] = le
    
    # å¹´åº¦ã®å‡¦ç†ï¼ˆæ—¢ã«æ•°å€¤ãªã®ã§ãã®ã¾ã¾ï¼‰
    # å¹´åº¦ã®å‘¨æœŸæ€§ã‚’è€ƒæ…®ã—ãŸç‰¹å¾´é‡
    if 'Year' in df_new.columns:
        df_new['Year_sin'] = np.sin(2 * np.pi * (df_new['Year'] - df_new['Year'].min()) / 
                                   (df_new['Year'].max() - df_new['Year'].min()))
        df_new['Year_cos'] = np.cos(2 * np.pi * (df_new['Year'] - df_new['Year'].min()) / 
                                   (df_new['Year'].max() - df_new['Year'].min()))
    
    print("ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")
    return df_new, encoders

def prepare_final_dataset(df, train_len):
    """æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™"""
    # ä½¿ç”¨ã—ãªã„åˆ—ã‚’é™¤å¤–
    exclude_cols = ['Id', 'Drafted']
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    
    # æ•°å€¤å‹ä»¥å¤–ã®åˆ—ãŒã‚ã‚Œã°ç¢ºèª
    non_numeric_cols = df[feature_cols].select_dtypes(exclude=[np.number]).columns
    if len(non_numeric_cols) > 0:
        print(f"è­¦å‘Š: æ•°å€¤å‹ä»¥å¤–ã®åˆ—ãŒã‚ã‚Šã¾ã™: {list(non_numeric_cols)}")
        # å¼·åˆ¶çš„ã«æ•°å€¤å‹ã«å¤‰æ›
        for col in non_numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # ç„¡é™å¤§ã‚„æ¥µç«¯ã«å¤§ããªå€¤ã®å‡¦ç†
    for col in feature_cols:
        if col in df.columns:
            # ç„¡é™å¤§ã‚’ NaN ã«å¤‰æ›
            df[col] = df[col].replace([np.inf, -np.inf], np.nan)
            
            # æ®‹ã£ãŸ NaN ã‚’ä¸­å¤®å€¤ã§è£œå®Œ
            if df[col].isnull().sum() > 0:
                df[col].fillna(df[col].median(), inplace=True)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
    train_processed = df[:train_len].copy()
    test_processed = df[train_len:].copy()
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†é›¢
    X_train = train_processed[feature_cols]
    y_train = train_processed['Drafted']
    X_test = test_processed[feature_cols]
    
    print(f"ç‰¹å¾´é‡æ•°: {len(feature_cols)}")
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {X_train.shape}")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {X_test.shape}")
    print(f"æ¬ æå€¤ç¢ºèª - è¨“ç·´: {X_train.isnull().sum().sum()}, ãƒ†ã‚¹ãƒˆ: {X_test.isnull().sum().sum()}")
    
    return X_train, y_train, X_test, feature_cols

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
print("\n1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
train = pd.read_csv('data/train.csv')
test = pd.read_csv('data/test.csv')
sample_submission = pd.read_csv('data/sample_submission_6_20ä¿®æ­£.csv')

print(f"Train: {train.shape}, Test: {test.shape}")

# ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒï¼‰
train_fe = train.copy()
test_fe = test.copy()

# å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãŸã‚ï¼‰
all_data = pd.concat([train_fe, test_fe], ignore_index=True)

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
all_data_fe = create_basic_features(all_data)
all_data_fe = create_position_features(all_data_fe)
all_data_fe = create_school_features(all_data_fe)
all_data_fe = advanced_missing_value_handling(all_data_fe)
all_data_fe, label_encoders = encode_categorical_features(all_data_fe)

# æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
X_train_fe, y_train_fe, X_test_fe, feature_cols_fe = prepare_final_dataset(all_data_fe, len(train))

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ãƒ»è©•ä¾¡
def evaluate_ensemble_model(X_train, y_train, n_splits=5, random_state=42):
    """3æ‰‹æ³•ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®äº¤å·®æ¤œè¨¼è©•ä¾¡"""
    
    # Stratified K-Foldè¨­å®š
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    
    # ã‚¹ã‚³ã‚¢æ ¼ç´ç”¨
    cv_scores = []
    individual_scores = {'RandomForest': [], 'LightGBM': [], 'XGBoost': []}
    
    print("\n2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« 5-Foldäº¤å·®æ¤œè¨¼å®Ÿè¡Œä¸­...")
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    rf_params = {
        'n_estimators': 200,
        'max_depth': 10,
        'min_samples_split': 10,
        'min_samples_leaf': 5,
        'random_state': random_state,
        'n_jobs': -1
    }
    
    lgb_params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.1,
        'feature_fraction': 0.8,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'min_child_samples': 20,
        'verbosity': -1,
        'random_state': random_state
    }
    
    xgb_params = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'max_depth': 6,
        'learning_rate': 0.1,
        'n_estimators': 1000,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'min_child_weight': 1,
        'reg_alpha': 0.1,
        'reg_lambda': 1,
        'random_state': random_state,
        'verbosity': 0
    }
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
        
        # 1. RandomForestãƒ¢ãƒ‡ãƒ«
        rf_model = RandomForestClassifier(**rf_params)
        rf_model.fit(X_fold_train, y_fold_train)
        rf_pred = rf_model.predict_proba(X_fold_val)[:, 1]
        rf_score = roc_auc_score(y_fold_val, rf_pred)
        individual_scores['RandomForest'].append(rf_score)
        
        # 2. LightGBMãƒ¢ãƒ‡ãƒ«
        train_dataset = lgb.Dataset(X_fold_train, label=y_fold_train)
        val_dataset = lgb.Dataset(X_fold_val, label=y_fold_val, reference=train_dataset)
        
        lgb_model = lgb.train(
            lgb_params,
            train_dataset,
            valid_sets=[train_dataset, val_dataset],
            valid_names=['train', 'valid'],
            num_boost_round=1000,
            callbacks=[
                lgb.early_stopping(stopping_rounds=100, verbose=False),
                lgb.log_evaluation(period=0)
            ]
        )
        lgb_pred = lgb_model.predict(X_fold_val, num_iteration=lgb_model.best_iteration)
        lgb_score = roc_auc_score(y_fold_val, lgb_pred)
        individual_scores['LightGBM'].append(lgb_score)
        
        # 3. XGBoostãƒ¢ãƒ‡ãƒ«
        xgb_model = xgb.XGBClassifier(**xgb_params)
        xgb_model.fit(X_fold_train, y_fold_train)
        xgb_pred = xgb_model.predict_proba(X_fold_val)[:, 1]
        xgb_score = roc_auc_score(y_fold_val, xgb_pred)
        individual_scores['XGBoost'].append(xgb_score)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆå¹³å‡ï¼‰
        ensemble_pred = (rf_pred + lgb_pred + xgb_pred) / 3
        ensemble_score = roc_auc_score(y_fold_val, ensemble_pred)
        cv_scores.append(ensemble_score)
        
        print(f"Fold {fold}: RF={rf_score:.5f}, LGB={lgb_score:.5f}, XGB={xgb_score:.5f}, Ensemble={ensemble_score:.5f}")
    
    # çµæœã®é›†è¨ˆ
    mean_score = np.mean(cv_scores)
    std_score = np.std(cv_scores)
    
    print(f"\n=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« æœ€çµ‚çµæœ ===")
    print(f"å¹³å‡ROC AUC: {mean_score:.5f} Â± {std_score:.5f}")
    
    # å„æ‰‹æ³•ã®å¹³å‡ã‚¹ã‚³ã‚¢è¨ˆç®—
    rf_mean = np.mean(individual_scores['RandomForest'])
    lgb_mean = np.mean(individual_scores['LightGBM'])
    xgb_mean = np.mean(individual_scores['XGBoost'])
    
    print(f"\n=== å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«çµæœï¼ˆä»Šå›ã®Foldï¼‰ ===")
    print(f"RandomForest : {rf_mean:.5f} Â± {np.std(individual_scores['RandomForest']):.5f}")
    print(f"LightGBM     : {lgb_mean:.5f} Â± {np.std(individual_scores['LightGBM']):.5f}")
    print(f"XGBoost      : {xgb_mean:.5f} Â± {np.std(individual_scores['XGBoost']):.5f}")
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« : {mean_score:.5f} Â± {std_score:.5f}")
    
    # éå»ã®æœ€é«˜è¨˜éŒ²ã¨ã®æ¯”è¼ƒ
    best_individual = max(0.83743, 0.83873, 0.84419)  # éå»ã®æœ€é«˜è¨˜éŒ²
    print(f"\n=== æ”¹å–„åº¦åˆ†æ ===")
    print(f"éå»ã®æœ€é«˜è¨˜éŒ²: XGBoost (0.84419)")
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: {mean_score:.5f}")
    
    if mean_score > best_individual:
        improvement = ((mean_score - best_individual) / best_individual) * 100
        print(f"ğŸ‰ æ–°è¨˜éŒ²é”æˆ! +{improvement:.2f}% æ”¹å–„")
    elif mean_score > 0.80792:
        improvement = ((mean_score - 0.80792) / 0.80792) * 100
        print(f"âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ”¹å–„: +{improvement:.2f}%")
    else:
        decline = ((0.80792 - mean_score) / 0.80792) * 100
        print(f"âš ï¸  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ä¸‹å›ã‚Š: -{decline:.2f}%")
    
    return cv_scores, rf_params, lgb_params, xgb_params

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡å®Ÿè¡Œ
cv_scores_ensemble, rf_best_params, lgb_best_params, xgb_best_params = evaluate_ensemble_model(X_train_fe, y_train_fe)

# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬
def create_ensemble_submission(X_train, y_train, X_test, test_ids, rf_params, lgb_params, xgb_params, random_state=42):
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§æœ€çµ‚çš„ãªæå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    
    print("\n3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")
    
    # 1. RandomForestæœ€çµ‚ãƒ¢ãƒ‡ãƒ«
    rf_final = RandomForestClassifier(**rf_params)
    rf_final.fit(X_train, y_train)
    rf_test_pred = rf_final.predict_proba(X_test)[:, 1]
    
    # 2. LightGBMæœ€çµ‚ãƒ¢ãƒ‡ãƒ«
    train_dataset = lgb.Dataset(X_train, label=y_train)
    lgb_final = lgb.train(
        lgb_params,
        train_dataset,
        num_boost_round=1000,
        callbacks=[lgb.log_evaluation(period=0)]
    )
    lgb_test_pred = lgb_final.predict(X_test)
    
    # 3. XGBoostæœ€çµ‚ãƒ¢ãƒ‡ãƒ«
    xgb_final_params = xgb_params.copy()
    
    xgb_final = xgb.XGBClassifier(**xgb_final_params)
    xgb_final.fit(X_train, y_train)
    xgb_test_pred = xgb_final.predict_proba(X_test)[:, 1]
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ï¼ˆå˜ç´”å¹³å‡ï¼‰
    ensemble_test_pred = (rf_test_pred + lgb_test_pred + xgb_test_pred) / 3
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    submission = pd.DataFrame({
        'Id': test_ids,
        'Drafted': ensemble_test_pred
    })
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    submission_filename = 'ensemble_submission.csv'
    submission.to_csv(submission_filename, index=False)
    
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {submission_filename}")
    print(f"äºˆæ¸¬å€¤ã®çµ±è¨ˆ:")
    print(f"  å¹³å‡: {ensemble_test_pred.mean():.4f}")
    print(f"  ä¸­å¤®å€¤: {np.median(ensemble_test_pred):.4f}")
    print(f"  æœ€å°å€¤: {ensemble_test_pred.min():.4f}")
    print(f"  æœ€å¤§å€¤: {ensemble_test_pred.max():.4f}")
    print(f"  æ¨™æº–åå·®: {ensemble_test_pred.std():.4f}")
    
    # å€‹åˆ¥äºˆæ¸¬ã®æ¯”è¼ƒ
    print(f"\nå„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµ±è¨ˆ:")
    print(f"RandomForest - å¹³å‡: {rf_test_pred.mean():.4f}, æ¨™æº–åå·®: {rf_test_pred.std():.4f}")
    print(f"LightGBM     - å¹³å‡: {lgb_test_pred.mean():.4f}, æ¨™æº–åå·®: {lgb_test_pred.std():.4f}")
    print(f"XGBoost      - å¹³å‡: {xgb_test_pred.mean():.4f}, æ¨™æº–åå·®: {xgb_test_pred.std():.4f}")
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« - å¹³å‡: {ensemble_test_pred.mean():.4f}, æ¨™æº–åå·®: {ensemble_test_pred.std():.4f}")
    
    return submission, rf_final, lgb_final, xgb_final

# ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€çµ‚æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
test_ids = test['Id'].values
final_submission_ensemble, rf_final_model, lgb_final_model, xgb_final_model = create_ensemble_submission(
    X_train_fe, y_train_fe, X_test_fe, test_ids, rf_best_params, lgb_best_params, xgb_best_params
)

# ç·åˆã¾ã¨ã‚
print(f"\n=== ğŸ† æœ€çµ‚æˆæœã¾ã¨ã‚ ===")
print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³      : 0.80792")
print(f"RandomForest      : 0.83743 Â± 0.02740")
print(f"LightGBM          : 0.83873 Â± 0.01730")
print(f"XGBoost           : 0.84419 Â± 0.02425")
print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«      : {np.mean(cv_scores_ensemble):.5f} Â± {np.std(cv_scores_ensemble):.5f}")

# æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ç‰¹å®š
all_scores = {
    'RandomForest': 0.83743,
    'LightGBM': 0.83873,
    'XGBoost': 0.84419,
    'Ensemble': np.mean(cv_scores_ensemble)
}

best_model = max(all_scores, key=all_scores.get)
best_score = all_scores[best_model]

print(f"\nğŸ† æœ€çµ‚æœ€é«˜ã‚¹ã‚³ã‚¢: {best_model} ({best_score:.5f})")
print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ”¹å–„: +{((best_score - 0.80792) / 0.80792) * 100:.2f}%")

print(f"\n=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿè£…å®Œäº† ===")
print(f"- æå‡ºãƒ•ã‚¡ã‚¤ãƒ«: ensemble_submission.csv")
print(f"- å…¨æ‰‹æ³•ã®çµ±åˆå®Œäº†")
print(f"- æ¬¡ã®æ¨å¥¨ä½œæ¥­: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆOptunaï¼‰") 